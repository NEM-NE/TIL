# 모두의 딥러닝 3강

## Minimize Cost

- Hypothesis and Cost

### Hypothesis and Cost

![스크린샷 2022-05-05 오후 10.29.43.png](%E1%84%86%E1%85%A9%E1%84%83%E1%85%AE%E1%84%8B%E1%85%B4%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%203%E1%84%80%E1%85%A1%E1%86%BC%200a4aa24e1afd4033a11def3e0711be51/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-05_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_10.29.43.png)

직접 가설을 세우고 Cost를 계산을 해보자

![스크린샷 2022-05-05 오후 10.32.10.png](%E1%84%86%E1%85%A9%E1%84%83%E1%85%AE%E1%84%8B%E1%85%B4%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%203%E1%84%80%E1%85%A1%E1%86%BC%200a4aa24e1afd4033a11def3e0711be51/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-05_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_10.32.10.png)

 

 위 예시처럼 여러 가설들을 만들어보고 y축이 cost값이고 x축이 w인 그래프를 그리면 다음과 같다.

![스크린샷 2022-05-05 오후 10.33.46.png](%E1%84%86%E1%85%A9%E1%84%83%E1%85%AE%E1%84%8B%E1%85%B4%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%203%E1%84%80%E1%85%A1%E1%86%BC%200a4aa24e1afd4033a11def3e0711be51/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-05_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_10.33.46.png)

이를 기계적으로 찾을 수 있는 방법은 Gradient Descent Algorithm(경사를 따라 내려가는 알고리즘)이다.

- cost function의 최소값을 찾는 데 사용
- 많은 최소화 문제에서 사용
- cost 함수와 w, b를 입력하면 최적의 w, b를 알려준다.
- 위 예시 뿐만이 아니라 일반적인 상황에서도 적용이 가능하다

동작원리 → 기울기(미분을 하면 알 수 있다 )를 따라 움직이면서 기울기가 0인 곳을 찾는다.

아무 지점에서 시작을 해서 W와 b의 값을 계속 조금씩 바꾼다. cost를 줄이는 방향으로

![스크린샷 2022-05-05 오후 10.41.48.png](%E1%84%86%E1%85%A9%E1%84%83%E1%85%AE%E1%84%8B%E1%85%B4%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%203%E1%84%80%E1%85%A1%E1%86%BC%200a4aa24e1afd4033a11def3e0711be51/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-05_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_10.41.48.png)

Convex Func

![스크린샷 2022-05-05 오후 10.44.09.png](%E1%84%86%E1%85%A9%E1%84%83%E1%85%AE%E1%84%8B%E1%85%B4%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%203%E1%84%80%E1%85%A1%E1%86%BC%200a4aa24e1afd4033a11def3e0711be51/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-05_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_10.44.09.png)

위 상황처럼 시작점에 따라 w, b값이 달라질 수 있음 → Gradient Descent 알고리즘이 제대로 동작 X

그래서 Cost Func이 Convex Func인지 확인할 것 (Convex Func이면 알고리즘 적용 가능)

![스크린샷 2022-05-05 오후 10.45.16.png](%E1%84%86%E1%85%A9%E1%84%83%E1%85%AE%E1%84%8B%E1%85%B4%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%203%E1%84%80%E1%85%A1%E1%86%BC%200a4aa24e1afd4033a11def3e0711be51/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-05_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_10.45.16.png)