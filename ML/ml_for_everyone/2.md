# 모두의 딥러닝 2강

## Simple Linear Regression

- Regression
- Linear Regression
- Hypothesis
- Which hypothesis is better?
- Cost, Cost function
- Goal: Minimize cost

### Regression

→ “Regression toward the mean” - 전체의 평균으로 되돌아간다.

### Linear Regression

→ 데이터를 가장 잘 대변하는 직선의 방정식으로 표현한 것

학습이란 **H(x) = Wx + b**로 표현하는 가설을 세운다.

여러 가설들 중에서 현재 데이터를 가장 잘 대변하는 가설을 선택한다.

가장 잘 대변하는 가설을 찾기 위해 cost을 생각해야한다.

비용은 실제 결과 데이터 y와 가설의 결과 데이터의 차이이며 cost가 작을수록 정확하다

![스크린샷 2022-05-05 오후 10.14.17.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d14fd44a-d22b-43ec-aeac-adb45dbdf702/스크린샷_2022-05-05_오후_10.14.17.png)

![스크린샷 2022-05-05 오후 10.15.29.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0487ed5e-4552-44cc-9eb9-a8a8a2b2011a/스크린샷_2022-05-05_오후_10.15.29.png)

그러나 결과 값이 음수가 나올 수 있고 양수가 나올 수 있기 때문에 

제곱을 한뒤 평균을 낸 것을 일반적으로 사용한다.

**즉, 딥러닝의 목표는 cost함수의 결과값을 최소화시킬 수 있는 w,b를 찾는 것이다.**