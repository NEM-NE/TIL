# 6주차 정리

# Service

파드는 일시적인 존재이기 때문에 언제든지 IP가 변경될 수 있다. 클라이언트 입장에서 변하는 IP 주소에 대응하기 어렵기 때문에 서비스라는 오브젝트를 통해 관리한다.

## 서비스 개요 복습

**파드는 매번 기동될 때마다 대표 IP가 바뀌므로 서비스를 통해 통신을 해야한다.** 

![Untitled](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/Untitled.png)

1. **서비스는 로드밸런서의 역할을 가지며, 클라이언트의 요청을 받기 위한 대표 IP 주소를 획득한다.**
2. 서비스의 이름은 내부 DNS에 등록되기 때문에 클라이언트는 **서비스의 이름만으로 서비스의 IP 주소획득가능**
3. 서비스는 셀렉터에 지정된 라벨과 일치하는 파드 중 하나에게 요청을 전달한다.
    
    **파드는 기동될 때 `라벨`, `IP 정보`를 마스터 노드 프로세스 중 하나인 `etcd`에 저장** 이후 etcd에서 조회하여 파드의 IP 주소 획득
    
4. 기동된 파드의 컨테이너에는 서비스에 대한 정보가 담긴 환경 변수가 자동으로 설정된다.
5. 클라이언트 범위에 따라 **4종류의 서비스**가 존재하며 클러스터 내부, 외부, 외부의 IP주소 등으로 나뉨.
    
    ![스크린샷, 2022-05-18 오전 2.18.10.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-18_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_2.18.10.png)
    

**중요 키워드**

- 대표 IP 주소 ⇒ 파드의 그룹을 대표하여 클라이언트의 요청을 받기 위해 가짐
- 부하분산 ⇒ 서비스는 셀렉터에 지정된 라벨과 일치하는 파드 중 하나에게 요청을 전달한다.
- 이름 해결 ⇒ **서비스의 이름은 내부 DNS에 등록되기** 때문에 클라이언트는 서비스의 이름만으로 서비스의 IP 주소획득가능
- 환경 변수 ⇒ 기동된 파드의 컨테이너에는 서비스에 대한 정보가 담긴 환경 변수가 자동으로 설정된다.
    
    → 서비스의 IP주소도 얻을 수 있다.
    
- 어피니티 ⇒ **파드를 특정 노드에 배포되도록 하는 정책**으로 파드가 특정 Node에 배포되는 Node affinity와 다른 파드가 배포된 노드를 기준으로 하는 Pod affinity가 있다.
- 셀렉터와 라벨
    - 라벨 : 파드등의 오브젝트가 가지는 키값
    - 셀렉터 : 라벨에 대한 조건

## ClusterIP

→ 서비스의 기본 설정 타입으로 클러스터 내부에서 내부 DNS에 등록한 이름으로 특정 파드 집합에 요청을 보낼 수 있다.

![스크린샷, 2022-05-18 오전 2.21.47.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-18_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_2.21.47.png)

→ 여기서 클라이언트는 kubectl이 아닌 파드인데 즉, 외부 클라이언트는 요청을 할 수 없는 내부 대표 IP를 통해 요청을 보낸다.

추가로 `헤드리스 설정`으로 서비스를 동작할 수 있는데 여기서 헤드리스 설정은 대표 IP 주소를 획득하지 않고, 부하분산도 이뤄지지 않지만 **파드들의 IP 주소를 내부 DNS에 등록하여 파드의 IP 주소 변경에 대응하여 최신상태를 유지한다.**

→ 헤드리스 설정은 MSA에서는 `서비스 디스커버리`와 똑같다. 서비스 디스커비리는 요청하고 싶은 서비스의 엔드 포인트를 서비스 레지스트리가 저장하여 서비스의 IP가 변하더라도 클라이언트는 서비스의 레지스트리에게만 요청을 하면 되기 때문에 상관없었다. **마찬가지로 내부 DNS에 파드의 IP를 저장하여 사용할 수 있게 해놓음**

### 실습

위 2개의 YAML를 실행하고 `kubectl get all` 하면 다음과 같은 결과가 나온다.

![스크린샷 2022-05-21 오후 4.01.31.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_4.01.31.png)

이때 기존 디플로이먼트와 함께 서비스에 `web-service`가 추가된 것을 확인할 수 있다.

새로운 busybox 파드를 만들어서 `http://web-service`나 `http://10.102.8.183`으로 접속하면 실제로 연결되는 것을 확인할 수 있다.

또한 서비스를 만든 후 모든 파드에는 서비스와 관련된 환경 변수가 설정되어 있다.

![스크린샷 2022-05-21 오후 4.04.47.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_4.04.47.png)

![스크린샷 2022-05-21 오후 4.11.16.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_4.11.16.png)

실제로 지속적으로 요청을 보내면 부하분산 처리하는 것을 확인 할 수 있다.

만약 동일한 클라이언트에게 온 요청을 계속 동일한 파드에서 처리하고 싶다면 `sessionAffinity`를 사용하면 된다.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  selector:
    app: web
  ports:
  - protocol: TCP
    port: 80
  sessionAffinity: ClientIP
```

[쿠버네티스 #7 - 서비스 (Service)](https://bcho.tistory.com/1262)

[MSA에서 Service discovery 패턴](https://bcho.tistory.com/1252)

## NodePort

→ 클러스터 내부에서 통신할 수 있게 해주는 Cluster IP 기능에 더해 **클러스터 외부에서 통신할 수 있게 해준다.**

→ 노드의 IP 주소에 공개 포트가 열린다.

![스크린샷 2022-05-21 오후 3.32.37.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.32.37.png)

- NodePort 서비스를 만들면 클러스터의 모든 노드에 지정한 포트(30000 ~ 32767)가 열린다.
- 서비스는 요청을 받으면 대상이 되는 파드들에게 부하분산되어 전송한다. (다른 노드의 파드에도 부하분산이 됨)

### 실습

간단한 Nginx 컨테이너 기반인 파드로 구성된 디플로이먼트와 Nodeport가 설정된 서비스를 실행시킨다.

기본 클러스터 구성에서는 kubectl get svc를 통해 나온 포트번호를 이용해서 구할 수 있지만 미니쿠베 환경에서는 개별적으로 설정해줘야한다.

먼저 `minikube service 서비스이름 --url`을 실행해준다.

이후에 `ps -ef | grep docker@127.0.0.1` 명령어를 입력해주고 해당 결과를 잘 보면 Cluster IP + Port를 바인딩해주는 부분을 찾을 수 있다. 이후 해당 포트번호에 `127.0.0.1:바인딩된_포트번호`를 입력해주면 된다.

![스크린샷 2022-05-21 오후 7.55.49.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7.55.49.png)

![스크린샷 2022-05-21 오후 8.15.08.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_8.15.08.png)

## LoadBalancer

→ 클라우드 로드밸런서와 연동하여 파드의 애플리케이션을 외부에 공개한다.

→ NodePort를 사용하기 때문에 ClusterIP도 자동적으로 생성

![스크린샷 2022-05-21 오후 3.37.01.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.37.01.png)

- 퍼블릭 클라우드에서는 각 업체가 제공하는 로드밸런서가 연동
- 보안을 위해서 https 적용을 위해 각 파드에서 HTTPS 암호화 처리를 하거나 인그레스 컨트롤러를 이용한다.

## ExternalName

→ 파드에서 K8s 외부 엔드포인트에 접속하기 위해 사용

→ 네임스페이스에서 서비스 이름으로 IP 주소를 얻을 수 있기 때문

![스크린샷 2022-05-21 오후 3.42.17.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.42.17.png)

- 서비스명과 외부 DNS 주소를 내부 DNS에 등록한다.

![스크린샷 2022-05-21 오후 8.22.37.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_8.22.37.png)

## 서비스와 파드의 연결

→ 서비스가 요청을 전송할 파드를 결정할 때 파드의 메타데이터가 저장된 etcd에서 일치하는 셀렉터의 라벨를 찾고 찾으면 IP 주소를 반환함으로서 특정 파드에게 요청을 할 수 있다.

![스크린샷 2022-05-21 오후 3.47.32.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.47.32.png)

실제로 서비스 YAML과 디플로이먼트 YAML을 보면 `app: web`이라는 동일한 라벨 설정을 해줬다.

![스크린샷 2022-05-21 오후 3.51.10.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.51.10.png)

![스크린샷 2022-05-21 오후 3.51.17.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-21_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.51.17.png)

```yaml
## 디플로이먼트
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-deploy
spec:
  replicas: 3
  selector:           # deployment - pod 대응용
    matchLabels:
      app: web
  template:           # 여기서부터 파드 템플릿
    metadata:
      labels:
        app: web      # 파드의 라벨
    spec:
      containers:
      - name: nginx
        image: nginx:latest
```

```yaml
## 서비스
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:                 # type을 생략하여 ClusterIP가 적용된다.
  selector:           # service - 백엔드 pod와 연결
    app: web
  ports:
  - protocol: TCP
    port: 80
```

# 잡과 크론잡

→ 실패 시 재실행하는 잡과 특정 스케줄에 맞춰 동작하는 크론잡

![스크린샷 2022-05-22 오전 12.13.18.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.13.18.png)

### 잡의 특징

- Job Controller에서 Job은 `배치 처리`를 의미한다.
- 지정한 횟수와 병행 개수에 따라서 포드가 생성된다.
- **파드 내에 모든 컨테이너**가 성공적으로 종료되어야 종료 & 하나라도 실패하면 전부 비정상 종료로 취급
- 정상 종료되거나 재실행 횟수 초과시 잡은 종료된다.
- 노드 장애에 의해 잡의 파드가 제거되면 다른 노드에서 실행
- 잡에 의해 실행된 파드는 **잡이 삭제될 때(종료 아님)까지 유지**

![스크린샷 2022-05-22 오전 12.17.55.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.17.55.png)

### 크론잡의 특징

- 일정한 스케줄에 맞춰 잡을 생성
- **생성된 파드의 개수가 정해진 수를 넘어서면 종료된 파드를 `가비지 수집 컨트롤러`가 종료된 파드를 삭제한다.**

## 잡 활용 예

- 동시 실행과 순차 실행
    - 상호 독립적으로 처리할 수 있는 배치 처리라면 병렬적으로 처리하는 것이 더 빠를 것
        - 대량 메일 발송, 이미지 * 동영상 * 음원 파일의 변환처리 등
- 온라인 배치 처리 요청
    
    ![스크린샷 2022-05-22 오전 12.23.56.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.23.56.png)
    
    - 잡과 메시지 브로커를 조합
- 정기 실행 배치 처리
    - 데이터의 백업이나 매시간마다 실행되는 배치 처리
    

## 잡의 실행 수와 동시 실행 수

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: normal-end
spec:
  template:
    spec:
      containers:
      - name: busybox
        image: busybox:latest
        command: ["sh",  "-c", "sleep 5; exit 0"]
      restartPolicy: Never
  completions: 6 # 총 실행 횟수
	parallelism: 2 # 병렬 실행하는 파드 개수
```

![스크린샷 2022-05-22 오전 12.32.19.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.32.19.png)

## 하나의 컨테이너로 구성된 파드가 이상 종료 되는 경우

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: abnormal-end
spec:
  backoffLimit: 3 # 실패에 대한 최대 시행횟수
  template:
    spec:
      containers:
      - name: busybox
        image: busybox:latest
        command: ["sh",  "-c", "sleep 5; exit 1"] # 비정상 종료
      restartPolicy: Never
```

![스크린샷 2022-05-22 오전 12.37.47.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.37.47.png)

5초뒤에 비정상 종료 되도록 설정을 했기 때문에 backoffLimit 설정에 따라 3번 더 기동하였다.

이후 `BackoffLimitExceeded`라는 경고를 출력

그에 따른 해당 결과는 아래와 같이 나온다.

![스크린샷 2022-05-22 오전 12.38.46.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.38.46.png)

추가로 여러 컨테이너 중 일부가 이상 종료 할 때의 동작은 다음과 같다.

![스크린샷 2022-05-22 오전 12.43.46.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.43.46.png)

![스크린샷 2022-05-22 오전 12.43.58.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.43.58.png)

파드에서 1개의 컨테이너만 계속 실행이 안되기 때문에 최종적으로 backoffLimit를 초과한다.

## 소수 계산 컨테이너와 잡 컨트롤러

→ 잡 컨트롤러는 수치 계산 관련 처리에 자주 사용된다.

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: prime-number
spec:
  template:
    spec:
      containers:
      - name: pn-generator
        image: maho/pn_generator:0.1 # 소수를 찾아주는 도커 컨테이너 이미지
        env: # 컨테이너 내부 환경 변수 설정
        - name: A_START_NUM
          value: "2"
        - name: A_SIZE_NUM
          value: "10**5"
      restartPolicy: Never
  backoffLimit: 4
```

![스크린샷 2022-05-22 오전 12.52.17.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.52.17.png)

→ 로그를 통해 확인할 수 있다.

## 메시지 브로커와의 조합

→ 위 예시는 하나의 컨테이너가 처리하고 있다. 만약 큰 데이터를 다루게 된다면 메모리 용량에 제한과 성능 저하가 발생할 것이다.

이를 해결하기 위해 병렬적으로 계산범위를 나눠 여러파드들에게 할당해주는 것

그러나 범위를 나눠 일일이 매니페스트에 할당해주는 것도 문제

→ 계산범위를 메세지 브로커가 받아 쿠버네티스 API를 통해 동적으로 매니페스트를 만든다. ~ 병렬 처리 가능

![스크린샷 2022-05-22 오전 1.03.00.png](6%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20a77a0e5428b14819a7e55aa082ef6781/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-22_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_1.03.00.png)

1. Job Initiator는 계산할 범위를 분할하여 큐에 전송 & 병렬 수와 반복횟수를 지정하여 잡 컨트롤러의 오브젝트를 생성
2. RabbitMQ는 디플로이먼트로 배포 & 쿠버네티스 외부에 있는 JobInitiator가 접근할 수 있도록 NodePort서비스 사용
3. 잡 컨트롤러는 Job Initiator에 의해 생성
    
    ```python
    def create_job_manifest(n_job, n_node):
        container = client.V1Container(
            name="pn-generator",
            image="maho/pn_generator:0.7",
            env=[
                client.V1EnvVar(name="BROKER_URL",value="amqp://guest:guest@taskqueue:5672"),
                client.V1EnvVar(name="QUEUE",value="taskqueue")
            ]
        )
        template = client.V1PodTemplateSpec(
            spec=client.V1PodSpec(containers=[container],
                                  restart_policy="Never"                              
            ))
        spec = client.V1JobSpec(
            backoff_limit=4,
            template=template,
            completions=n_job,
            parallelism=n_node)
        job = client.V1Job(
            api_version="batch/v1",
            kind="Job",
            metadata=client.V1ObjectMeta(name=OBJECT_NAME),
            spec=spec)
        return job
    ```
    
4. RabbitMQ에서 계산 범위를 입력 받아 표준 출력으로 출력